{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a7cdbc2-992d-4ff3-9aba-24397ff78132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -U langgraph langchain-community langchain-anthropic tavily-python langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T13:32:13.272723Z",
     "start_time": "2025-02-10T13:32:11.408877Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d39aa6201847ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T13:32:18.742179Z",
     "start_time": "2025-02-10T13:32:14.004554Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = pd.read_csv('data/amazon_categories.csv')\n",
    "products = pd.read_csv('data/amazon_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8177e9c9-708d-4f8d-ad15-7bf01fb72061",
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = pd.read_csv('data/ecommerce_faq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2096d9-c12a-4440-b0f5-c2ca23eab24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asin', 'title', 'imgUrl', 'productURL', 'stars', 'reviews', 'price',\n",
       "       'listPrice', 'category_id', 'isBestSeller', 'boughtInLastMonth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93c4162-4be7-46b0-8742-7ceb09dba349",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.replace(0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a15488-264a-4d60-ad2d-8cc4f5df14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1426337 entries, 0 to 1426336\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   asin               1426337 non-null  object\n",
      " 1   title              1426336 non-null  object\n",
      " 2   imgUrl             1426337 non-null  object\n",
      " 3   productURL         1426337 non-null  object\n",
      " 4   stars              1426337 non-null  object\n",
      " 5   reviews            1426337 non-null  object\n",
      " 6   price              1426337 non-null  object\n",
      " 7   listPrice          1426337 non-null  object\n",
      " 8   category_id        1426337 non-null  int64 \n",
      " 9   isBestSeller       1426337 non-null  bool  \n",
      " 10  boughtInLastMonth  1426337 non-null  object\n",
      "dtypes: bool(1), int64(1), object(9)\n",
      "memory usage: 110.2+ MB\n"
     ]
    }
   ],
   "source": [
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c567704c-841c-4247-bc61-dba6a4809e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories.rename(columns={\n",
    "'id':'category_id'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504b72fe-f00b-4b7a-a215-463fbd8ff266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(products, categories, on='category_id')  # Default is inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1398da0a-c622-40ed-b01d-76bb5c7efab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c91003e-e7e5-407c-be9e-b4a4605e518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>imgUrl</th>\n",
       "      <th>productURL</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>listPrice</th>\n",
       "      <th>category_id</th>\n",
       "      <th>isBestSeller</th>\n",
       "      <th>boughtInLastMonth</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B014TMV5YE</td>\n",
       "      <td>Sion Softside Expandable Roller Luggage, Black...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/815dLQKYIY...</td>\n",
       "      <td>https://www.amazon.com/dp/B014TMV5YE</td>\n",
       "      <td>4.5</td>\n",
       "      <td></td>\n",
       "      <td>139.99</td>\n",
       "      <td></td>\n",
       "      <td>104</td>\n",
       "      <td>False</td>\n",
       "      <td>2000</td>\n",
       "      <td>Suitcases</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title  \\\n",
       "0  B014TMV5YE  Sion Softside Expandable Roller Luggage, Black...   \n",
       "\n",
       "                                              imgUrl  \\\n",
       "0  https://m.media-amazon.com/images/I/815dLQKYIY...   \n",
       "\n",
       "                             productURL stars reviews   price listPrice  \\\n",
       "0  https://www.amazon.com/dp/B014TMV5YE   4.5          139.99             \n",
       "\n",
       "   category_id  isBestSeller boughtInLastMonth category_name  \n",
       "0          104         False              2000     Suitcases  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e52e90-30f2-4e80-85d8-4c888e989fad",
   "metadata": {},
   "source": [
    "# Clip Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8557c963-9a95-4f20-b61d-5981339debf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "image_paths = [img for img in df[\"imgUrl\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc36ab88-e843-4d57-b4cc-7f3c945ec29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426336"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac1f64a-9a74-4ef1-9849-a5e457e7985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62516ecd-3eac-4134-a4a1-780d4eb63c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from tqdm import tqdm  \n",
    "from torchvision import transforms\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "463c2899-db02-4d8e-95ff-2687c3e11a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emann\\Documents\\GitHub\\MultiModal-E-Commerce-Customer-Support-Chatbot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emann\\anaconda3\\envs\\nst\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\\\Users\\\\emann\\\\Documents\\\\GitHub\\\\MultiModal-E-Commerce-Customer-Support-Chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2fb89c0-3217-45f5-8968-aa0610b89f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\emann\\\\Documents\\\\GitHub\\\\MultiModal-E-Commerce-Customer-Support-Chatbot'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a28b5-b3a8-4a98-a576-ee7ced4cca22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edca56e7-b933-48a2-91e3-41059f03d984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_urls = df['imgUrl'][].tolist()\n",
    "\n",
    "img_embeddings = []\n",
    "products_url = []\n",
    "\n",
    "for url in img_urls:\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      embeddings = model.encode_image(img_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    img_embeddings.append(embeddings)\n",
    "    products_url.append(url)\n",
    "\n",
    "  except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")  # Skip failed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f17d1-639a-4d54-bc2f-3cf2ed73cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for img_path in tqdm(image_paths, desc=\"Extracting Embeddings\", unit=\"image\"):\n",
    "    try:\n",
    "        embeddings.append(get_image_embedding(img_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {img_path}: {e}\")  # Just log and move on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575ce8b-f869-4468-9a2b-d5fac081ce72",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "538f4605-6701-46b6-9918-1135f8788a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-groq) (0.3.34)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (24.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.2.3)\n",
      "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: langchain-groq\n",
      "Successfully installed langchain-groq-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b2aeae-2555-4cf4-bff1-eb963b89b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fca396f-92fc-4efc-9fe3-d72c1041974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23eaa13-ac57-4634-9b16-479234f26cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emann\\AppData\\Local\\Temp\\ipykernel_8256\\3414252995.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95df800e-f543-4f99-9079-be7f354cb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faq_texts = [f\"FAQ: {row['Question']} Answer: {row['Answer']}\" for _, row in faq.iterrows()]\n",
    "product_texts = [f\"Product: {row['title']} Price: ${row['price']} Category: {row['category_name']} Image: {row['imgUrl']}\" for _, row in df.iterrows()]\n",
    "\n",
    "all_texts = faq_texts + product_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c57cdcd7-612b-4eff-b5cc-9d0287d1ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faq_texts = [f\"FAQ: {row['Question']} Answer: {row['Answer']}\" for _, row in faq.iterrows()]\n",
    "product_texts = [f\"Product: {row['title']} Price: ${row['price']} Category: {row['category_name']} Image: {row['imgUrl']}\" for _, row in df.iterrows()]\n",
    "\n",
    "all_texts = faq_texts + product_texts\n",
    "\n",
    "documents = [Document(page_content=text) for text in all_texts]\n",
    "\n",
    "faiss_index = FAISS.from_documents(documents, embed_model)\n",
    "faiss_index.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2df040-48ab-469f-8448-b93d3d52192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Care Bears 22077 14 Inch Medium Plush Togetherness Bear, Collectable Cute Plush Toy, Cuddly Toys for Children, Soft Toys for Girls and Boys, Cute Teddies Suitable for Girls and Boys Aged 4 Years + Price: $ Category: Stuffed Animals & Plush Toys Image: https://m.media-amazon.com/images/I/71bCBVDTyGS._AC_UL320_.jpg\n"
     ]
    }
   ],
   "source": [
    "faiss_index = FAISS.load_local(\"faiss_index\", embed_model, allow_dangerous_deserialization=True)\n",
    "query = \"I want a teady bear\"\n",
    "docs = faiss_index.similarity_search(query, k=1)\n",
    "retrieved_info = docs[0].page_content if docs else \"No relevant information found.\"\n",
    "print(retrieved_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc47cca-a695-4a4e-b0fa-2e6841ff70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "# llm = ChatGroq(model_name=\"llama-3-70b-versatile\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca2662-35fc-419e-94b1-71af84567a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04034255-8a56-490a-8005-863a92977d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emann\\AppData\\Local\\Temp\\ipykernel_8256\\2202291290.py:46: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages = True, memory_key = 'chat_history',\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Recommend a phone under $500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Assistant:  Based on our product database, I'd like to recommend the **VTech IS8151-5 Super Long Range 5 Handset DECT 6.0 Cordless Phone for Home**. It's a great option that fits your budget of under $500, priced at $136.20.\n",
      "\n",
      "This phone features a super long range of 2300 ft, an answering machine, call blocking, Bluetooth, a headset jack, power backup, intercom, and is expandable to 12 handsets. It's a great value for its price and has received positive reviews from customers.\n",
      "\n",
      "Would you like to know more about this product or explore other options within your budget?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  can i see the image as well?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Assistant:  I apologize, but I don't have the specific product \"VTech IS8151-5 Super Long Range 5 Handset DECT 6.0 Cordless Phone for Home\" in my database. However, I can suggest some other options that fit your budget of under $500.\n",
      "\n",
      "Here are a few products from my database:\n",
      "\n",
      "* **VTech CS6529-4B 4-Handset DECT 6.0 Cordless Phone with Answering System and Caller ID**: This phone is priced at $86.79 and has the following image: https://m.media-amazon.com/images/I/71+kzN3iLeL._AC_UL320_.jpg\n",
      "* **VTech CS6124 DECT 6.0 Cordless 2K DCI 1080p Phone with Answering System and Caller ID/Call Waiting**: This phone is priced at [no price available] and has the following image: https://m.media-amazon.com/images/I/81+pnSPxKAL._AC_UL320_.jpg\n",
      "* **VTech VG101-11 DECT 6.0 Cordless Phone for Home**: This phone is priced at $18.45 and has the following image: https://m.media-amazon.com/images/I/71imBgvdhYL._AC_UL320_.jpg\n",
      "\n",
      "Please let me know if you'd like more information about any of these products or if you'd like to explore other options within your budget.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  i meant iphone?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Assistant:  I apologize for the confusion! Based on your original query, I see that we have an iPhone option in our database.\n",
      "\n",
      "Here's a recommendation:\n",
      "\n",
      "* **Apple iPhone 12 Pro Max, 128GB, Pacific Blue - AT&T (Renewed)**: This iPhone is priced at $510.00 and has the following image: https://m.media-amazon.com/images/I/41ZCg7l8N6L._AC_UL320_.jpg\n",
      "\n",
      "Please note that this is a renewed iPhone, which means it's a pre-owned device that has been inspected and tested to meet manufacturer standards.\n",
      "\n",
      "Would you like to know more about this product or explore other iPhone options within your budget?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  oh its too much\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Assistant:  The Apple iPhone 12 Pro Max is a bit pricey.\n",
      "\n",
      "Let me suggest a more affordable option:\n",
      "\n",
      "* **Apple iPhone 11, 64GB, White - Fully Unlocked (Renewed)**: This iPhone is priced at $298.46 and has the following image: https://m.media-amazon.com/images/I/31PY10NqSLL._AC_UL320_.jpg\n",
      "\n",
      "This is a renewed iPhone 11, which is a more budget-friendly option. Would you like to know more about this product or explore other iPhone options within your budget?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Assistant:  It was nice chatting with you! If you need any assistance in the future, feel free to reach out. Have a great day!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_conversation_chain(vectorDB):\n",
    "    llm = ChatGroq(api_key='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',\n",
    "                   model_name = 'llama3-70b-8192', temperature = 0)\n",
    "\n",
    "    prompt_shopping_assistant = \"\"\"\n",
    "    *Welcome Message:*\n",
    "    \"Hi there! I'm your Shopping Assistant. I'll be happy to help in your shopping journey. How may I assist you today?\"\n",
    "    *Your role* \".\n",
    "    \n",
    "    *User Interaction:*\n",
    "    - *Query Received*: {input}\n",
    "    - *Your Database*: {context}\n",
    "        Use this as your primary knowledge base.\n",
    "\n",
    "    *Guidelines for Usage of Database:*\n",
    "    \n",
    "    1. I operate strictly within the bounds of our product database. If an inquiry is about topics outside our catalog, I will suggest alternatives or ask for more details about our products.\n",
    "       For instance: \"I can only assist with questions about our products. Can you specify which one youâ€™re interested in?\"\n",
    "    2. If the context is irrelevant based on the user query or if the required product information is missing, don't refer to the mismatched context or make assumptions.\n",
    "       Instead, directly ask the user to provide more specific details or shift their inquiry to a different product that is available in our database.\n",
    "    3. When the context you get does not align with the user's query or if the required product information is not in our database, clearly state:\n",
    "       \"I apologize, but I don't have any information on that particular product. Could you please specify another product or feature you are interested in?\"\n",
    "       This keeps the conversation focused and encourages users to ask about other products we might have information on.\n",
    "       \n",
    "    *Strict Restrictions*:\n",
    "        - I can only use the provided knowledge base to answer queries.\n",
    "        - I am not allowed to provide any support except for product-related queries.\n",
    "        - I will refuse any non-product-related queries without explanation.\n",
    "        - I will not attempt to answer questions outside my product-related scope.\n",
    "        - I will provide concise and direct responses.\n",
    "        - I will strictly adhere to all the above guidelines.\n",
    "\n",
    "    *Execution Standards*:\n",
    "        - My responses will be succinct, precise, and tailored to your specific inquiries.\n",
    "        - I will maintain a professional tone throughout our interaction.\n",
    "        - I will use proper text formatting for better readability.\"\"\"\n",
    "    \n",
    "    prompt_chatbot = ChatPromptTemplate.from_messages([('system', prompt_shopping_assistant),\n",
    "                     MessagesPlaceholder('chat_history'), ('human', '{input}')])\n",
    "\n",
    "    context_retriever = create_history_aware_retriever(llm,\n",
    "                        vectorDB.as_retriever(), prompt_chatbot)\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt_chatbot)\n",
    "    conversation_chain = create_retrieval_chain(context_retriever, document_chain)\n",
    "    memory = ConversationBufferMemory(return_messages = True, memory_key = 'chat_history',\n",
    "                                      output_key = 'result', input_key = 'input')\n",
    "    return conversation_chain, memory\n",
    "\n",
    "def main(input_dict):\n",
    "    vectorDB_path = input_dict['vectorDB_path']\n",
    "    vectorDB = FAISS.load_local(vectorDB_path,\n",
    "               HuggingFaceEmbeddings(model_name = 'all-MiniLM-L6-v2'),\n",
    "               allow_dangerous_deserialization = True)\n",
    "\n",
    "    conversation_chain, memory = get_conversation_chain(vectorDB)\n",
    "    while True:\n",
    "        user_input = input('User: ')\n",
    "\n",
    "        documents_retrieved = vectorDB.similarity_search(user_input, threshold=0.9)\n",
    "        if not documents_retrieved:\n",
    "            response = \"I apologize, but I don't have any information on that particular product. Could you please specify another product or feature you are interested in?\"\n",
    "        else:\n",
    "            context = \" \".join([doc.page_content for doc in documents_retrieved if 'page_content' in doc])\n",
    "        chain_input = {'input': user_input, 'chat_history': memory.chat_memory.messages, 'context': context}\n",
    "\n",
    "        result = conversation_chain.invoke(chain_input)\n",
    "        response = result['answer']\n",
    "        print('-'*80)\n",
    "        print('Assistant: ', response)\n",
    "        print('-'*80)\n",
    "        memory.save_context({'input': user_input}, {'result': response})\n",
    "\n",
    "input_dict = {'vectorDB_path': 'faiss_index'}\n",
    "main(input_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2163dc5-bbdc-46dc-bc40-c2a3afbe828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: openai-clip in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: ftfy in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from openai-clip) (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from openai-clip) (2024.11.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from ftfy->openai-clip) (0.2.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emann\\anaconda3\\envs\\nst\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers openai-clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45e74ea3-9b7e-43ed-bc41-f2727d2f48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "307c47cc-3081-47d4-b179-f967964fc7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bc017-ac29-4267-b46b-66ae3cfd0d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# Process image\n",
    "image = Image.open(\"uploaded_image.jpg\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "image_embedding = model.get_image_features(**inputs)\n",
    "\n",
    "# Search for similar products\n",
    "similar_products = faiss_db.similarity_search(image_embedding, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nst]",
   "language": "python",
   "name": "conda-env-nst-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
